# -*- coding: utf-8 -*-
"""Breast Cancer Detection Google CoLab .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BL2Vzfs3I4JHUJ-OzhGuV27kQiAqcGbS
"""

import numpy as np 
import pandas as pd 
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")

from sklearn import linear_model #for logistic regression
from sklearn.neural_network import MLPClassifier #for neural network
from sklearn.model_selection import KFold, GridSearchCV, cross_val_score, cross_val_predict, validation_curve 
from sklearn.ensemble import VotingClassifier #for creating ensembles of classifiers

from google.colab import files
uploaded = files.upload()
data = pd.read_csv('data.csv')

data = data.dropna(axis=1)
data.pop('id')
data["diagnosis"] = [1 if i.strip() == "M" else 0 for i in data.diagnosis]

y = data.diagnosis.values
x = data.drop(['diagnosis'], axis=1)

from random import randrange
from random import seed
 
# Split a dataset into a train and test set
def train_test_split(dataset, split=0.7):
	train = list()
	train_size = split * len(dataset)
	dataset_copy = list(dataset)
	while len(train) < train_size:
		index = randrange(len(dataset_copy))
		train.append(dataset_copy.pop(index))
	return train, dataset_copy

x

# test train/test split
seed(1)
X_dataset = x.values
X_train, X_test = train_test_split(X_dataset)
print(X_train)
print(Y_test)

seed(1)
Y_dataset = y
Y_train, Y_test = train_test_split(Y_dataset)
print(Y_train)
print(Y_test)

"""x = data.iloc[:,2:] 
y = data.iloc[:,1]
print (x.shape, y.shape)

columns = x.columns
columns

X_train

X_test

scalar = StandardScaler()
X_train = scaler.fit_transform(X_train) 
X_test = scaler.transform(X_test)

from random import randrange
 
# Split a dataset into k folds
def cross_validation_split(dataset, folds=2):
	dataset_split = list()
	dataset_copy = list(dataset)
	fold_size = int(len(dataset) / folds)
	for i in range(folds):
		fold = list()
		while len(fold) < fold_size:
			index = randrange(len(dataset_copy))
			fold.append(dataset_copy.pop(index))
		dataset_split.append(fold)
	return dataset_split

seed(1)
X__dataset = X_train
X_folds = cross_validation_split(X__dataset, 4)
print(X_folds)

seed(1)
Y__dataset = Y_train
Y_folds = cross_validation_split(Y__dataset, 4)
print(Y_folds)

"""test_size = 0.3
X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = test_size, random_state = 22)
print("X_train",len(X_train))
print("X_test",len(X_test))
print("Y_train",len(Y_train))
print("Y_test",len(Y_test))"""

logreg = linear_model.LogisticRegression()
rg = regressor.fit(X_train, Y_train)

y_pred_train = regressor.predict(X_train)
y_pred_test = regressor.predict(X_test)
#y_pred_val = regressor.predict(X_val)


acc_test = accuracy_score(Y_test, y_pred_test) 
acc_train = accuracy_score(Y_train, y_pred_train)
#acc_val = accuracy_score(Y_val, y_pred_val)


cm_test = confusion_matrix(Y_test, y_pred_test)
cm_train = confusion_matrix(Y_train, y_pred_train)
#cm_val = confusion_matrix(Y_val, y_pred_val)


print("test accuracy: ", acc_test)
print("CM Test: \n",cm_test)
print("----------------------------------------------------")
print("train accuracy: ", acc_train)
print("CM Train: \n",cm_train)
#print("----------------------------------------------------")
#print("val accuracy: ", acc_val)
#print("CM Val: \n",cm_val)

logreg = linear_model.LogisticRegression()

kfold = KFold(n_splits=2)

cv_results = cross_val_score(logreg, x, y, cv=kfold)

print (cv_results.mean()*100, "%")

num_splits = 5
num_C_values = 10 # we iterate over 10 possible C values
logreg = linear_model.LogisticRegression()
kfold = KFold(n_splits=5)
C_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]
train_scores, valid_scores = validation_curve(logreg, x_norm, y, "C", C_values, cv=kfold)
train_scores = pd.DataFrame(data=train_scores, index=np.arange(0, num_C_values), columns=np.arange(0,num_splits)) 
valid_scores = pd.DataFrame(data=valid_scores, index=np.arange(0, num_C_values), columns=np.arange(0,num_splits)) 
plt.semilogx(C_values, train_scores.mean(axis=1), label='training score')
plt.semilogx(C_values, valid_scores.mean(axis=1), label='test score')
plt.xlabel('C')
plt.legend()

clf = MLPClassifier(solver='lbfgs', random_state=1, activation='logistic', hidden_layer_sizes=(15,))
kfold = KFold(n_splits=5,random_state=7)
cv_results = cross_val_score(clf, x_norm, y, cv=kfold)
print (cv_results.mean()*100, "%")

clf = MLPClassifier(solver='lbfgs', random_state=1, activation='logistic',  hidden_layer_sizes=(15,))
param_grid = {"alpha":10.0 ** -np.arange(-4, 7)}
grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv=kfold)
grid.fit(x_norm,y)
print (grid.best_estimator_)
print (grid.best_score_*100, "%")

logreg = linear_model.LogisticRegression(C=0.1)
kfold = KFold(n_splits=5,random_state=7)
cv_results = cross_val_score(logreg, x_norm, y, cv=kfold)
predicted = cross_val_predict(logreg, x_norm, y, cv=kfold)
diff = predicted - y
misclass_indexes = diff[diff != 0].index.tolist()
print (misclass_indexes)

clf = MLPClassifier(solver='lbfgs', random_state=1, activation='logistic', alpha=1.0, hidden_layer_sizes=(15,))
kfold = KFold(n_splits=5,random_state=7)
cv_results = cross_val_score(clf, x_norm, y, cv=kfold)
predicted = cross_val_predict(clf, x_norm, y, cv=kfold)
diff = predicted - y
misclass_indexes = diff[diff != 0].index.tolist()
print (misclass_indexes)

clf1 = linear_model.LogisticRegression(C=0.1)
clf2 = MLPClassifier(solver='lbfgs', alpha=1.0,hidden_layer_sizes=(15,), random_state=1, activation='logistic')

eclf = VotingClassifier(estimators=[('lr', clf1), ('nn', clf2)], voting='soft', weights=[2,1])

cv_results = cross_val_score(eclf, x_norm, y, cv=kfold)

print (cv_results.mean()*100, "%")



from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

# actual values
actual = y.values
# predicted values
predicted = predicted

# confusion matrix
matrix = confusion_matrix(actual,predicted, labels=[1,0])
print('Confusion matrix : \n',matrix)

# outcome values order in sklearn
tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)
print('Outcome values : \n', tp, fn, fp, tn)

# classification report for precision, recall f1-score and accuracy
matrix = classification_report(actual,predicted,labels=[1,0])
print('Classification report : \n',matrix)