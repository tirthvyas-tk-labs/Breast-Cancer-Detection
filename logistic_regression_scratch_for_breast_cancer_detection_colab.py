# -*- coding: utf-8 -*-
"""Logistic_Regression_scratch for Breast cancer Detection CoLab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12NUozXPbeRqmTVqczTpAAsW_FlGGDFIH
"""

from numpy import array
from sklearn.model_selection import KFold

import numpy as np 
import pandas as pd 
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import ListedColormap

from google.colab import files
uploaded = files.upload()
data = pd.read_csv('data.csv')

data = data.dropna(axis=1)
data.pop('id')
data["diagnosis"] = [1 if i.strip() == "M" else 0 for i in data.diagnosis]

y = data.diagnosis.values
x = data.drop(['diagnosis'], axis=1)

columns = x.columns
columns

corr_matrix = data.corr()



plt.figure(figsize=(20,10))
sns.heatmap(corr_matrix,annot = True, fmt = ".2f")
plt.title("Correlation Between Features")
plt.show()

threshold = 0.6
filtre = np.abs(corr_matrix["diagnosis"]) > threshold 
corr_features = corr_matrix.columns[filtre].tolist()
sns.heatmap(data[corr_features].corr(), annot = True, fmt = ".2f")
plt.title("Correlation Between Features w Corr Theshold 0.75")
plt.show()

# Plotting the histograms of each variable
from matplotlib import pyplot
data.hist(alpha=0.5, figsize=(30, 30))
pyplot.show()

# data x
#data = x.values
# prepare cross validation
#kfold = KFold(2, True, 1)
# enumerate splits
#for X_train, X_test in kfold.split(data): print('train: %s, test: %s' % (data[X_train], data[X_test]))

#X_train = pd.DataFrame(X_train, columns = columns)

#X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=2)

#X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=2)

data

scaler = StandardScaler()
x = scaler.fit_transform(x)

test_size = 0.3
X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = test_size, random_state = 22)
print("X_train",len(X_train))
print("X_test",len(X_test))
print("Y_train",len(Y_train))
print("Y_test",len(Y_test))
print("========================")
#print("X_val",len(X_val))
#print("Y_val",len(Y_val))

"""scaler = StandardScaler()
X_train = scaler.fit_transform(X_train) 
X_test = scaler.transform(X_test)
#X_val = scaler.transform(X_val)

X_train

X_test

#X_train = pd.DataFrame(X_train, columns = columns)

from sklearn.metrics import accuracy_score

class LogisticRegressionoftk:

    def __init__(self, learning_rate=0.001, n_iters=3000):
        self.lr = learning_rate
        self.n_iters = n_iters
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        n_samples, n_features = X.shape

        # init parameters
        self.weights = np.zeros(n_features)
        self.bias = 0

        # gradient descent
        for _ in range(self.n_iters):
            # approximate y with linear combination of weights and x, plus bias
            linear_model = np.dot(X, self.weights) + self.bias
            # apply sigmoid function
            y_predicted = self._sigmoid(linear_model)

            # compute gradients
            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))
            db = (1 / n_samples) * np.sum(y_predicted - y)
            # update parameters
            self.weights -= self.lr * dw
            self.bias -= self.lr * db

    def predict(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        y_predicted = self._sigmoid(linear_model)
        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]
        return np.array(y_predicted_cls)

    def _sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

regressor = LogisticRegressionoftk(learning_rate = 0.01, n_iters=2000)
rg = regressor.fit(X_train, Y_train)

y_pred_train = regressor.predict(X_train)
y_pred_test = regressor.predict(X_test)
#y_pred_val = regressor.predict(X_val)


acc_test = accuracy_score(Y_test, y_pred_test) 
acc_train = accuracy_score(Y_train, y_pred_train)
#acc_val = accuracy_score(Y_val, y_pred_val)


cm_test = confusion_matrix(Y_test, y_pred_test)
cm_train = confusion_matrix(Y_train, y_pred_train)
#cm_val = confusion_matrix(Y_val, y_pred_val)


print("test accuracy: ", acc_test)
print("CM Test: \n",cm_test)
print("----------------------------------------------------")
print("train accuracy: ", acc_train)
print("CM Train: \n",cm_train)
#print("----------------------------------------------------")
#print("val accuracy: ", acc_val)
#print("CM Val: \n",cm_val)

fpr1, tpr1, thresh1 = roc_curve(Y_test, y_pred_test, pos_label=1)

plt.style.use('seaborn')

plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')

plt.title('TEST ROC curve ')

plt.xlabel('False Positive Rate')

plt.ylabel('True Positive rate')

plt.legend(loc='best')
plt.savefig('ROC',dpi=600)
plt.show();

fpr1, tpr1, thresh1 = roc_curve(Y_train, y_pred_train, pos_label=1)

plt.style.use('seaborn')

plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')

plt.title('TRAIN ROC curve')

plt.xlabel('False Positive Rate')

plt.ylabel('True Positive rate')

plt.legend(loc='best')
plt.savefig('ROC',dpi=600)
plt.show();